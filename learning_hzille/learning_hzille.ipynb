{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Io8eIGlQ4Yl2"
   },
   "outputs": [],
   "source": [
    "def connect_to_gdrive():\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJEoafTBnNm8"
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision pytorch_lightning lightly torchsummary matplotlib sklearn pillow numpy pandas tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EiimOKNJT2at"
   },
   "outputs": [],
   "source": [
    "!pip install plotly==5.5.0 pyyaml==5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BdfZL7v23Qga"
   },
   "outputs": [],
   "source": [
    "#!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DG67fAwVnMrO"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "After a note in a lightning tutorial a batch size of 256 and image resolution of\n",
    "64x64px and the resnet-18 model from lightning lib will require 16GB GPU memory.\n",
    "todo: is that so? can we measure that some how?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# todo: check if all imports are needed/used\n",
    "\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder, DatasetFolder, VisionDataset\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import lightly\n",
    "from lightly.models.modules.heads import SimCLRProjectionHead\n",
    "from lightly.loss import NTXentLoss\n",
    "\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZA3J0q-60UGf"
   },
   "outputs": [],
   "source": [
    "global_config = {\n",
    "    'input_size': 128,\n",
    "    #'input_size': 224,\n",
    "    'projection_head_out': 128,\n",
    "    'pretraining-batchsize': 1024,\n",
    "    'finetuning-batchsize': 128, #256\n",
    "    'pretraining-epochs': 20,\n",
    "    'finetuning-epochs': 40,\n",
    "    'pretraining-learningrate': 5e-4,  #6e-2\n",
    "    'finetuning-learningrate': 5e-5,  #5e-6 1e-4\n",
    "    'optimizer': 'Adam',  #'SGD'\n",
    "    'training_size': 0.7,\n",
    "    'test_size': 0.3,\n",
    "    'dew_dataset_size': 1,\n",
    "    'hzille_dataset_size': 1,\n",
    "    'random_seed': 2022,\n",
    "    'num_workers': 2,\n",
    "    'path_to_dew_data': 'drive/MyDrive/Data Sets/dew/until_1950/until_1950',\n",
    "    'path_to_hzille_data': 'drive/MyDrive/Data Sets/Heinrich Zille/ausgeschnitten_klein',\n",
    "    'load_dew_image_list_from_disk' : False,\n",
    "    'load_hzille_image_list_from_disk' : True,\n",
    "    'path_to_pickled_dew_file_names' : 'drive/MyDrive/Data Sets/dew/until_1950/until_1950.pickle',  # gets used instead of path to data to avoid reading all images from disk\n",
    "    'hzille_metadata_path': 'drive/MyDrive/Data Sets/Heinrich Zille/parsed_image_meta_data.csv',\n",
    "    'logs_base_folder': 'runs',\n",
    "    'plot_fig_size': (120, 60)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3vR2yJs7Wh6"
   },
   "outputs": [],
   "source": [
    "def load_image_lists(path_to_data, load_image_list_from_disk, dataset_size):\n",
    "    \"\"\"\n",
    "    Get all image file names in order to split dataset into train and test\n",
    "    \"\"\"\n",
    "    print()\n",
    "    print('Loading images list...')\n",
    "\n",
    "    print()\n",
    "    print('Start time: ', datetime.now())\n",
    "    print()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if load_image_list_from_disk:\n",
    "        print('...reading image list from disk...')\n",
    "\n",
    "        try:\n",
    "            all_images = os.listdir(path_to_data)\n",
    "        except OSError:\n",
    "            print('Error reading image list from', path_to_data)\n",
    "\n",
    "    else:\n",
    "        print('...loading image list previously stored...\\n')\n",
    "\n",
    "        path_to_pickled_data_file_names = path_to_data\n",
    "\n",
    "        opened_pickle_file = open(path_to_pickled_data_file_names, \"rb\")\n",
    "        all_images = pickle.load(opened_pickle_file)\n",
    "        opened_pickle_file.close()\n",
    "\n",
    "\n",
    "    selected_data_set_size = int(len(all_images) * dataset_size)\n",
    "    selected_image_set = np.random.choice(all_images, selected_data_set_size, replace=False)\n",
    "\n",
    "\n",
    "    print('End time: ', datetime.now())\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    total_mins = total_time / 60\n",
    "    print(f'Loading image file list took {round(total_mins, 1)} mins')\n",
    "\n",
    "    print('Number of all images:', len(all_images), all_images[:3])\n",
    "    print('Number of selected images:', len(selected_image_set), selected_image_set[:3])\n",
    "\n",
    "\n",
    "    return all_images, selected_image_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pgIT_AyY41Lv"
   },
   "outputs": [],
   "source": [
    "def get_training_and_test_filenames(training_size, test_size, _selected_image_set, seed):\n",
    "    \"\"\"\n",
    "    Split data filenames into train and test in order to create dataset objects with pytorch\n",
    "    \"\"\"\n",
    "\n",
    "    print()\n",
    "    print('Splitting images into train and test...')\n",
    "\n",
    "    train_filenames, test_filenames = train_test_split(\n",
    "        _selected_image_set, \n",
    "        shuffle=True, \n",
    "        train_size=training_size, \n",
    "        test_size=test_size, \n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    print('Training images:', len(train_filenames), 'Test image:', len(test_filenames))\n",
    "\n",
    "    return train_filenames, test_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfDjwODoA5_G"
   },
   "outputs": [],
   "source": [
    "def get_train_dataloader(input_size, collate_fn, path_to_data, file_names, batch_size, num_workers):\n",
    "    \n",
    "    print()\n",
    "    print('...creating train dataloader...')\n",
    "\n",
    "    print()\n",
    "    print('Start time: ', datetime.now())\n",
    "    print()\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if collate_fn is None:\n",
    "        #collate_fn = lightly.data.SimCLRCollateFunction(\n",
    "        #    input_size=input_size,\n",
    "        #    cj_prob=0,\n",
    "        #    random_gray_scale=1.0,\n",
    "        #    min_scale=0.3,\n",
    "        #    gaussian_blur=0.33,\n",
    "        #    kernel_size=0.03,\n",
    "        #    hf_prob=0.33\n",
    "        #    #vf_prob=0.5,\n",
    "        #    #rr_prob=0.5\n",
    "        #)\n",
    "        print('There should be a collate function passed....')\n",
    "        raise ValueError()\n",
    "\n",
    "    dataset_train = lightly.data.LightlyDataset(\n",
    "        input_dir=path_to_data,\n",
    "        filenames=file_names\n",
    "    )\n",
    "\n",
    "    _dataloader_train = torch.utils.data.DataLoader(\n",
    "        dataset_train,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "        drop_last=True,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    print('End time: ', datetime.now())\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    total_mins = total_time / 60\n",
    "    print(f'Creating dataset took {round(total_mins, 1)} mins')\n",
    "\n",
    "    return _dataloader_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ri8zAAyaCRsC"
   },
   "outputs": [],
   "source": [
    "def get_test_dataloader(input_size, path_to_data, file_names, batch_size, num_workers):\n",
    "    \n",
    "    print()\n",
    "    print('...creating test dataloader...')\n",
    "\n",
    "    print()\n",
    "    print('Start time: ', datetime.now())\n",
    "    print()\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    test_transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((input_size, input_size)),\n",
    "        torchvision.transforms.Grayscale(num_output_channels=1),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=np.mean(lightly.data.collate.imagenet_normalize['mean']),\n",
    "            std=np.mean(lightly.data.collate.imagenet_normalize['std']),\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    dataset_test = lightly.data.LightlyDataset(\n",
    "        input_dir=path_to_data,\n",
    "        filenames=file_names,\n",
    "        transform=test_transforms\n",
    "    )\n",
    "\n",
    "    dataloader_test = torch.utils.data.DataLoader(\n",
    "        dataset_test,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    print('End time: ', datetime.now())\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    total_mins = total_time / 60\n",
    "    print(f'Creating dataset took {round(total_mins, 1)} mins')\n",
    "\n",
    "    return dataloader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQTSIfKslAeJ"
   },
   "outputs": [],
   "source": [
    "class RandomGamma(torch.nn.Module):\n",
    "    \"\"\"Apply randomly gamma from torchvision functional transforms.\"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, p=0.5, gamma=(0.5, 1.5), gain=1):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.gamma = gamma\n",
    "        self.gain = gain\n",
    "\n",
    "\n",
    "    def forward(self, img):\n",
    "        \n",
    "        if self.p < torch.rand(1):\n",
    "            return img\n",
    "        \n",
    "        gamma = float(torch.empty(1).uniform_(self.gamma[0], self.gamma[1]))\n",
    "\n",
    "        return torchvision.transforms.functional.adjust_gamma(img, gamma, self.gain)\n",
    "    \n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(p={})'.format(self.p)\n",
    "\n",
    "def get_training_collate_fnc():\n",
    "\n",
    "    training_transforms = torchvision.transforms.Compose([\n",
    "        #HistogramNormalize(),\n",
    "        torchvision.transforms.RandomResizedCrop(size=global_config['input_size'], scale=(0.5, 1.0), ratio=(0.5, 2)),\n",
    "        torchvision.transforms.Grayscale(num_output_channels=1),\n",
    "        #torchvision.transforms.RandomHorizontalFlip(p=0.33),\n",
    "        #torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "        torchvision.transforms.GaussianBlur(kernel_size=21, sigma=(0.1, 1.0)),\n",
    "        torchvision.transforms.RandomInvert(p=0.2),\n",
    "        torchvision.transforms.RandomSolarize(threshold=128, p=0.2),\n",
    "        torchvision.transforms.RandomApply(\n",
    "            torch.nn.ModuleList([torchvision.transforms.ColorJitter(brightness=(0.2, 1.8), contrast=(0.2, 2.2), saturation=1, hue=0)]), \n",
    "            p=0.5\n",
    "        ),\n",
    "        RandomGamma(p=0.5, gamma=(0.025, 2), gain=1.05),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=np.mean(lightly.data.collate.imagenet_normalize['mean']),\n",
    "            std=np.mean(lightly.data.collate.imagenet_normalize['std']),\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    _collate_fnc = lightly.data.BaseCollateFunction(training_transforms)\n",
    "\n",
    "    return _collate_fnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4b-YAIpTsWuZ"
   },
   "outputs": [],
   "source": [
    "def load_dew_data(batch_size):\n",
    "    \n",
    "    all_images_list, selected_images_list = load_image_lists(\n",
    "        path_to_data=global_config['path_to_pickled_dew_file_names'],\n",
    "        load_image_list_from_disk=global_config['load_dew_image_list_from_disk'],\n",
    "        dataset_size=global_config['dew_dataset_size']\n",
    "    )\n",
    "\n",
    "    training_file_names, test_file_names = get_training_and_test_filenames(\n",
    "        training_size=global_config['training_size'],\n",
    "        test_size=global_config['test_size'],\n",
    "        _selected_image_set=selected_images_list,\n",
    "        seed=global_config['random_seed']\n",
    "    )\n",
    "\n",
    "    collate_fn = get_training_collate_fnc()\n",
    "\n",
    "    _dataloader_train = get_train_dataloader(\n",
    "        input_size=global_config['input_size'], \n",
    "        collate_fn=collate_fn,\n",
    "        path_to_data=global_config['path_to_dew_data'], \n",
    "        file_names=training_file_names, \n",
    "        batch_size=batch_size, \n",
    "        num_workers=global_config['num_workers']\n",
    "    )\n",
    "\n",
    "    _dataloader_test = get_test_dataloader(\n",
    "        input_size=global_config['input_size'],\n",
    "        path_to_data=global_config['path_to_dew_data'],\n",
    "        file_names=test_file_names,\n",
    "        batch_size=batch_size, \n",
    "        num_workers=global_config['num_workers']\n",
    "    )\n",
    "\n",
    "    return _dataloader_train, _dataloader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rndTWT0nvH5D"
   },
   "outputs": [],
   "source": [
    "def load_hzille_data(batch_size, get_full_dataset=False):\n",
    "    \n",
    "    all_images_list, selected_images_list = load_image_lists(\n",
    "        path_to_data=global_config['path_to_hzille_data'],\n",
    "        load_image_list_from_disk=global_config['load_hzille_image_list_from_disk'],\n",
    "        dataset_size=global_config['hzille_dataset_size']\n",
    "    )\n",
    "\n",
    "    if get_full_dataset:\n",
    "        \n",
    "        _dataloader_all = get_test_dataloader(\n",
    "            input_size=global_config['input_size'],\n",
    "            path_to_data=global_config['path_to_hzille_data'],\n",
    "            file_names=all_images_list,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=global_config['num_workers']\n",
    "        )\n",
    "\n",
    "        return _dataloader_all\n",
    "\n",
    "\n",
    "    training_file_names, test_file_names = get_training_and_test_filenames(\n",
    "        training_size=global_config['training_size'],\n",
    "        test_size=global_config['test_size'],\n",
    "        _selected_image_set=selected_images_list,\n",
    "        seed=global_config['random_seed']\n",
    "    )\n",
    "\n",
    "    collate_fn = get_training_collate_fnc()\n",
    "    \n",
    "    _dataloader_train = get_train_dataloader(\n",
    "        input_size=global_config['input_size'], \n",
    "        collate_fn=collate_fn,\n",
    "        path_to_data=global_config['path_to_hzille_data'], \n",
    "        file_names=training_file_names, \n",
    "        batch_size=batch_size, \n",
    "        num_workers=global_config['num_workers']\n",
    "    )\n",
    "\n",
    "    _dataloader_test = get_test_dataloader(\n",
    "        input_size=global_config['input_size'],\n",
    "        path_to_data=global_config['path_to_hzille_data'],\n",
    "        file_names=test_file_names,\n",
    "        batch_size=batch_size, \n",
    "        num_workers=global_config['num_workers']\n",
    "    )\n",
    "\n",
    "    return _dataloader_train, _dataloader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVdGoM202j1y"
   },
   "outputs": [],
   "source": [
    "class ResnetSimCLR(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_epochs,\n",
    "        batchsize,\n",
    "        projection_head_out,\n",
    "        learning_rate,\n",
    "        optimizer,\n",
    "        momentum=0.9,\n",
    "        weight_decay=1e-6,  #5e-4,\n",
    "        pretrained=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # configuration:\n",
    "        self.max_epochs = max_epochs\n",
    "        self.batchsize = batchsize\n",
    "        self.learning_rate = learning_rate\n",
    "        self.optimizer = optimizer\n",
    "        self.momentum = momentum\n",
    "        self.weight_decay = weight_decay\n",
    "        self.pretrained = pretrained\n",
    "\n",
    "        # load resnet\n",
    "        resnet = torchvision.models.resnet18(pretrained=self.pretrained)\n",
    "\n",
    "        # convert model to 1-channel without loosing pretrained weights like the fast.ai implementation\n",
    "        # from https://datascience.stackexchange.com/questions/65783/pytorch-how-to-use-pytorch-pretrained-for-single-channel-image\n",
    "        \n",
    "        # unpack model architecture / all layers\n",
    "        model_architecture = list(resnet.children())\n",
    "        \n",
    "        # store weights of first convolutions\n",
    "        first_conv_weight = model_architecture[0].weight\n",
    "\n",
    "        # replace original layer with new 1-channel convolutional layer\n",
    "        # original: (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        new_1_channel_conv = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        model_architecture[0] = new_1_channel_conv\n",
    "        \n",
    "        # convert original 3 dimensional weights to 1 dimension\n",
    "        model_architecture[0].weight = nn.Parameter(torch.mean(first_conv_weight, dim=1, keepdim=True))\n",
    "        \n",
    "        # pack architecture / layers again into sequential\n",
    "        model_architecture = nn.Sequential(*model_architecture)\n",
    "\n",
    "        # create backbone without original classification head\n",
    "        self.backbone = nn.Sequential(\n",
    "            *list(model_architecture.children())[:-1]\n",
    "        )\n",
    "\n",
    "        # create projection head\n",
    "        hidden_dim = resnet.fc.in_features\n",
    "\n",
    "        self.projection_head = SimCLRProjectionHead(\n",
    "            hidden_dim, hidden_dim, projection_head_out\n",
    "        )\n",
    "\n",
    "        # define loss function\n",
    "        self.criterion = NTXentLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # todo: for actual prediction the head should not be used!\n",
    "        h = self.backbone(x).flatten(start_dim=1)\n",
    "        z = self.projection_head(h)\n",
    "        \n",
    "        return z\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        (x0, x1), _, _ = batch\n",
    "        z0 = self.forward(x0)\n",
    "        z1 = self.forward(x1)\n",
    "        loss = self.criterion(z0, z1)\n",
    "        \n",
    "        self.log(\n",
    "            'train_loss', \n",
    "            loss, \n",
    "            on_step=True, \n",
    "            on_epoch=True, \n",
    "            batch_size=self.batchsize\n",
    "        )\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        if self.optimizer == 'SGD':\n",
    "            optim = torch.optim.SGD(\n",
    "                self.parameters(),\n",
    "                lr=self.learning_rate,  # 6e-2\n",
    "                momentum=self.momentum,\n",
    "                weight_decay=self.weight_decay\n",
    "            )\n",
    "\n",
    "        elif self.optimizer == 'Adam':\n",
    "            optim = torch.optim.Adam(\n",
    "                self.parameters(), \n",
    "                lr=self.learning_rate, # heuristically: 5e-4, initially: 1e-3\n",
    "                weight_decay=self.weight_decay  # initially: 1e-6\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError('Unknown optimizer: ', self.optimizer)    \n",
    "\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, self.max_epochs)\n",
    "        \n",
    "        return [optim], [scheduler]\n",
    "        #return optim\n",
    "\n",
    "\n",
    "    def set_learningrate(self, new_learningrate):\n",
    "        self.learning_rate = new_learningrate\n",
    "\n",
    "\n",
    "    def set_max_epochs(self, new_max_epochs):\n",
    "        self.max_epochs = new_max_epochs\n",
    "\n",
    "\n",
    "    def set_batchsize(self, new_batchsize):\n",
    "        self.batchsize = new_batchsize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t5QD0CcfC-on"
   },
   "outputs": [],
   "source": [
    "def get_model(_max_epochs, batchsize, projection_head_out, learning_rate, optimizer, pretrained=False, verbose=True):\n",
    "    \n",
    "    print()\n",
    "\n",
    "    _gpus = 1 if torch.cuda.is_available() else 0\n",
    "\n",
    "    model = ResnetSimCLR(\n",
    "        max_epochs=_max_epochs,\n",
    "        batchsize=batchsize, \n",
    "        projection_head_out=projection_head_out,\n",
    "        learning_rate=learning_rate,\n",
    "        optimizer=optimizer,\n",
    "        pretrained=pretrained\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "        print('gpus available:', torch.cuda.is_available())\n",
    "        print('gpus:', torch.cuda.device_count())\n",
    "        print('current device:', torch.cuda.current_device())\n",
    "        print('amount of gpus:', torch.cuda.device_count())\n",
    "        print('gpu name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "        #!nvidia-smi\n",
    "        \n",
    "        print('model total param:', sum(p.numel() for p in model.parameters()))\n",
    "        print('model total param:', sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "    return model, _gpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ip0ugfzDyNn"
   },
   "outputs": [],
   "source": [
    "def train_model(_model, _max_epochs, _gpus, dataloader, log_every_n_steps=10, _logger=True):\n",
    "    \"\"\"\n",
    "    Train model.\n",
    "    \"\"\"\n",
    "    print()\n",
    "    print('Training model...')\n",
    "\n",
    "    print()\n",
    "    print('Epochs:', _max_epochs)\n",
    "\n",
    "    print()\n",
    "    print('Start time: ', datetime.now())\n",
    "    print()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    _trainer = pl.Trainer(\n",
    "        logger=_logger,\n",
    "        max_epochs=_max_epochs,\n",
    "        gpus=_gpus,\n",
    "        log_every_n_steps=log_every_n_steps,\n",
    "        callbacks=pl.callbacks.progress.TQDMProgressBar()\n",
    "    )\n",
    "    #trainer.fit(model, tqdm(dataloader_train_simclr))\n",
    "    _trainer.fit(_model, dataloader)\n",
    "\n",
    "    print('End time: ', datetime.now())\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    total_mins = total_time / 60\n",
    "    print(f'Training took {round(total_mins, 1)} mins, ~{round(total_mins / _max_epochs, 1)} mins per epoch')\n",
    "\n",
    "    return _trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGRGtQcV6ciN"
   },
   "outputs": [],
   "source": [
    "def generate_embeddings(_model, dataloader):\n",
    "    \"\"\"\n",
    "    Used backbone of model (without projection head) accordingly to SimCLR paper\n",
    "    to create embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    print()\n",
    "    print('Generating embeddings...')\n",
    "\n",
    "    print()\n",
    "    print('Start time: ', datetime.now())\n",
    "    print()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    embeddings = []\n",
    "    filenames = []\n",
    "    with torch.no_grad():\n",
    "        for img, label, fnames in dataloader:\n",
    "            img = img.to(_model.device)\n",
    "            emb = _model.backbone(img).flatten(start_dim=1) # todo put into model as \".inference()\" or so\n",
    "            embeddings.append(emb)\n",
    "            filenames.extend(fnames)\n",
    "\n",
    "    embeddings = torch.cat(embeddings, 0)\n",
    "    embeddings = normalize(embeddings)\n",
    "    \n",
    "    print('End time: ', datetime.now())\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    total_mins = total_time / 60\n",
    "    print(f'Getting embeddings took {round(total_mins, 1)} mins')\n",
    "    \n",
    "    return embeddings, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7zZnk9-Q_Jz"
   },
   "outputs": [],
   "source": [
    "def get_knn(_embeddings, n_neighbours=3):\n",
    "\n",
    "    print()\n",
    "    print(f'Creating knn with {n_neighbours}...')\n",
    "\n",
    "    knn = NearestNeighbors(n_neighbors=n_neighbours).fit(_embeddings)\n",
    "\n",
    "    return knn\n",
    "\n",
    "\n",
    "def get_image_as_np_array(filename: str):\n",
    "    \"\"\"\n",
    "    Returns an image as an numpy array\n",
    "    \"\"\"\n",
    "    img = Image.open(filename)\n",
    "    grayscale_img = ImageOps.grayscale(img)\n",
    "\n",
    "    return np.asarray(grayscale_img)\n",
    "\n",
    "\n",
    "def plot_knn_examples(_knn, _embeddings, _filenames, path_to_data, num_examples=6, fig_size=(16,8), plot_saving_folder=None, seed=2022):\n",
    "    \"\"\"\n",
    "    Plots multiple rows of random images with their nearest neighbors\n",
    "\n",
    "    Most left image is query image, others are k-nearest neighbours.\n",
    "    Distance is displayed above images.\n",
    "    \"\"\"\n",
    "\n",
    "    print()\n",
    "    print(f'Plotting knn, {num_examples} examples...')\n",
    "\n",
    "    distances, indices = _knn.kneighbors(_embeddings)\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    samples_idx = np.random.choice(len(indices), size=num_examples, replace=False)\n",
    "    #print('sample indices', samples_idx)\n",
    "\n",
    "    for idx in samples_idx:\n",
    "        fig = plt.figure(figsize=fig_size)\n",
    "\n",
    "        for plot_x_offset, neighbor_idx in enumerate(indices[idx]):\n",
    "\n",
    "            ax = fig.add_subplot(1, len(indices[idx]), plot_x_offset + 1)\n",
    "            fname = os.path.join(path_to_data, _filenames[neighbor_idx])\n",
    "            plt.imshow(get_image_as_np_array(fname), cmap='gray', vmin=0, vmax=25\n",
    "            ax.set_title(f'd={distances[idx][plot_x_offset]:.3f} ({fname.split(\"/\")[-1]})')\n",
    "            plt.axis('off')\n",
    "        \n",
    "        if plot_saving_folder is not None:\n",
    "            \n",
    "            if not os.path.exists(plot_saving_folder):\n",
    "                os.makedirs(plot_saving_folder)\n",
    "            \n",
    "            fig.savefig(f'{plot_saving_folder}/{idx}_{_filenames[idx].split(\".\")[0]}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPcGP2hCQfDq"
   },
   "outputs": [],
   "source": [
    "def visualize_embeddings(\n",
    "    embeddings, \n",
    "    filenames, \n",
    "    path_to_store_data, \n",
    "    hzille_metadata_path\n",
    "):\n",
    "\n",
    "    tsne_3d = TSNE(\n",
    "        n_components=3, \n",
    "        random_state=global_config['random_seed'], \n",
    "        perplexity=15, \n",
    "        n_iter=5000,\n",
    "        n_iter_without_progress=500,\n",
    "        learning_rate=15\n",
    "    )\n",
    "\n",
    "    tsne_2d = TSNE(\n",
    "        n_components=2, \n",
    "        random_state=global_config['random_seed'], \n",
    "        perplexity=15, \n",
    "        n_iter=5000,\n",
    "        n_iter_without_progress=500,\n",
    "        learning_rate=15\n",
    "    )\n",
    "\n",
    "    pca_3d = PCA(\n",
    "        n_components=3, \n",
    "        random_state=global_config['random_seed']\n",
    "    )\n",
    "\n",
    "    pca_2d = PCA(\n",
    "        n_components=2, \n",
    "        random_state=global_config['random_seed']\n",
    "    )\n",
    "    \n",
    "    print('Reducing embeddings dimensions with...')\n",
    "    tsne_projections_3d = tsne_3d.fit_transform(embeddings)\n",
    "    tsne_projections_2d = tsne_2d.fit_transform(embeddings)\n",
    "    pca_components_3d = pca_3d.fit_transform(embeddings)\n",
    "    pca_components_2d = pca_2d.fit_transform(embeddings)\n",
    "\n",
    "    print('...creating plots...')\n",
    "\n",
    "    df_tsne_3d = pd.DataFrame(tsne_projections_3d)\n",
    "    df_tsne_2d = pd.DataFrame(tsne_projections_2d)\n",
    "    df_pca_3d = pd.DataFrame(pca_components_3d)\n",
    "    df_pca_2d = pd.DataFrame(pca_components_2d)\n",
    "\n",
    "    color_attribute = None\n",
    "    hover_data_attribute = None\n",
    "    \n",
    "    if hzille_metadata_path is not None:\n",
    "        \n",
    "        df_zille_metadata = pd.read_csv(hzille_metadata_path)\n",
    "    \n",
    "        df_tsne_3d['id'] = [int(filename.split('.')[0]) for filename in filenames]\n",
    "        df_tsne_2d['id'] = [int(filename.split('.')[0]) for filename in filenames]\n",
    "        df_pca_3d['id'] = [int(filename.split('.')[0]) for filename in filenames]\n",
    "        df_pca_2d['id'] = [int(filename.split('.')[0]) for filename in filenames]\n",
    "\n",
    "        # add authorship data to data frame\n",
    "        df_tsne_3d = pd.merge(left=df_tsne_3d, right=df_zille_metadata[['id', 'author']], on='id', how='inner')\n",
    "        df_tsne_2d = pd.merge(left=df_tsne_2d, right=df_zille_metadata[['id', 'author']], on='id', how='inner')\n",
    "        df_pca_3d = pd.merge(left=df_pca_3d, right=df_zille_metadata[['id', 'author']], on='id', how='inner')\n",
    "        df_pca_2d = pd.merge(left=df_pca_2d, right=df_zille_metadata[['id', 'author']], on='id', how='inner')\n",
    "\n",
    "        color_attribute = 'author'\n",
    "        hover_data_attribute = ['id']\n",
    "\n",
    "    fig_tsne_3d = px.scatter_3d(\n",
    "        df_tsne_3d,\n",
    "        x=0,\n",
    "        y=1,\n",
    "        z=2,\n",
    "        color=color_attribute,\n",
    "        hover_data=hover_data_attribute,\n",
    "        labels={\n",
    "            0: \"1st projection\",\n",
    "            1: \"2nd projection\",\n",
    "            2: \"3rd projection\"\n",
    "        },\n",
    "        title=\"t-SNE 3D\"\n",
    "    )\n",
    "    # fig.update_traces(marker_size=8)\n",
    "    fig_tsne_2d = px.scatter(\n",
    "        df_tsne_2d,\n",
    "        x=0,\n",
    "        y=1,\n",
    "        color=color_attribute,\n",
    "        hover_data=hover_data_attribute,\n",
    "        labels={\n",
    "            0: \"1st projection\",\n",
    "            1: \"2nd projection\"\n",
    "        },\n",
    "        title=\"t-SNE 2D\"\n",
    "    )\n",
    "    # fig.update_traces(marker_size=8)\n",
    "    fig_pca_3d = px.scatter_3d(\n",
    "        df_pca_3d,\n",
    "        x=0,\n",
    "        y=1,\n",
    "        z=2,\n",
    "        color=color_attribute,\n",
    "        hover_data=hover_data_attribute,\n",
    "        labels={\n",
    "            0: \"1st component\",\n",
    "            1: \"2nd component\",\n",
    "            2: \"3rd component\"\n",
    "        },\n",
    "        title=\"PCA 3D\"\n",
    "    )\n",
    "    # fig.update_traces(marker_size=8)\n",
    "    fig_pca_2d = px.scatter(\n",
    "        df_pca_2d,\n",
    "        x=0,\n",
    "        y=1,\n",
    "        color=color_attribute,\n",
    "        hover_data=hover_data_attribute,\n",
    "        labels={\n",
    "            0: \"1st component\",\n",
    "            1: \"2nd component\"\n",
    "        },\n",
    "        title=\"PCA 2D\"\n",
    "    )\n",
    "    # fig.update_traces(marker_size=8)\n",
    "\n",
    "    saving_folder = f'{path_to_store_data}/dim_reduction'\n",
    "\n",
    "    os.makedirs(saving_folder)\n",
    "    \n",
    "    df_tsne_3d.to_csv(f'{saving_folder}/tsne_3d.csv')\n",
    "    df_tsne_2d.to_csv(f'{saving_folder}/tsne_2d.csv')\n",
    "    df_pca_3d.to_csv(f'{saving_folder}/pca_3d.csv')\n",
    "    df_pca_2d.to_csv(f'{saving_folder}/pca_2d.csv')\n",
    "    \n",
    "    fig_tsne_3d.write_html(f'{saving_folder}/tsne_3d_plot.html')\n",
    "    fig_tsne_2d.write_html(f'{saving_folder}/tsne_2d_plot.html')\n",
    "    fig_pca_3d.write_html(f'{saving_folder}/pca_3d_plot.html')\n",
    "    fig_pca_2d.write_html(f'{saving_folder}/pca_2d_plot.html')\n",
    "    \n",
    "    fig_tsne_2d.show()\n",
    "    fig_pca_2d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2pgeghV_OZw"
   },
   "outputs": [],
   "source": [
    "def plot_data_augmentations(data_loader, rows=6, columns=12, figsize=(40, 20)):\n",
    "    \"\"\"\n",
    "    Sample from data augmentations\n",
    "    \"\"\"\n",
    "    batch_img_tuples, batch_labels, batch_filenames = next(iter(data_loader))\n",
    "    \n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    \n",
    "    img_channel = 0 # doesnÂ´t matter as all channels are gray here\n",
    "\n",
    "    image_idx = 0\n",
    "    for plot_position in range(1, columns * rows + 1, 2):\n",
    "    \n",
    "        fig.add_subplot(rows, columns, plot_position)\n",
    "        img_1 = batch_img_tuples[0][image_idx][img_channel].squeeze()\n",
    "        plt.imshow(img_1, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(batch_filenames[image_idx])\n",
    "\n",
    "        fig.add_subplot(rows, columns, plot_position + 1)\n",
    "        img_2 = batch_img_tuples[1][image_idx][img_channel].squeeze()\n",
    "        plt.imshow(img_2, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(batch_filenames[image_idx])\n",
    "\n",
    "        image_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Aa3q4oK9kD7"
   },
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    _experiment_name, \n",
    "    config, \n",
    "    pretrained, \n",
    "    test_data_loader, \n",
    "    pretraining_dataset_name=None, \n",
    "    pretraining_data_loader=None, \n",
    "    finetuning_dataset_name=None, \n",
    "    finetuning_data_loader=None,\n",
    "    pretraining_log_every_n_steps=10,\n",
    "    finetuning_log_every_n_steps=3,\n",
    "    model_from_checkpoint=None,\n",
    "    forced_batch_size_in_pretraining=None,\n",
    "    do_not_use_hzille_metadata=False\n",
    "):\n",
    "\n",
    "    training_options = ['dew', 'hzille', None]\n",
    "\n",
    "    assert pretraining_dataset_name in training_options\n",
    "    assert finetuning_dataset_name in training_options\n",
    "\n",
    "\n",
    "    if pretraining_data_loader:\n",
    "        \n",
    "        print('pretraining')\n",
    "        version_name = f'{datetime.now().strftime(\"%y-%m-%d-%H%M%S\")}_pretraining_{pretraining_dataset_name}'\n",
    "\n",
    "        logger = TensorBoardLogger(\n",
    "            save_dir=config['logs_base_folder'], \n",
    "            name=_experiment_name, \n",
    "            version=version_name\n",
    "        )\n",
    "\n",
    "        logger.log_hyperparams(config)\n",
    "\n",
    "        batch_size = forced_batch_size_in_pretraining if forced_batch_size_in_pretraining else config['pretraining-batchsize']\n",
    "        print('batch size:', batch_size)\n",
    "        pl.seed_everything(config['random_seed'])\n",
    "\n",
    "        model, gpus = get_model(\n",
    "            _max_epochs=config['pretraining-epochs'],\n",
    "            batchsize=batch_size,\n",
    "            projection_head_out=config['projection_head_out'],\n",
    "            learning_rate=config['pretraining-learningrate'],\n",
    "            optimizer=config['optimizer'],\n",
    "            pretrained=pretrained\n",
    "        )\n",
    "\n",
    "        trainer = train_model(\n",
    "            _model=model,\n",
    "            _max_epochs=config['pretraining-epochs'],\n",
    "            _gpus=gpus,\n",
    "            dataloader=pretraining_data_loader,\n",
    "            _logger=logger,\n",
    "            log_every_n_steps=pretraining_log_every_n_steps\n",
    "        )\n",
    "\n",
    "        trainer.save_checkpoint(f'{config[\"logs_base_folder\"]}/{_experiment_name}/{version_name}/final_model_checkpoints/{version_name}.ckpt')\n",
    "\n",
    "\n",
    "    if finetuning_data_loader:\n",
    "\n",
    "        print('finetuning')\n",
    "        version_name = f'{datetime.now().strftime(\"%y-%m-%d-%H%M%S\")}_finetuning_{finetuning_dataset_name}'\n",
    "\n",
    "        logger = TensorBoardLogger(\n",
    "            save_dir=config['logs_base_folder'], \n",
    "            name=_experiment_name, \n",
    "            version=version_name\n",
    "        )\n",
    "\n",
    "        logger.log_hyperparams(config)\n",
    "\n",
    "        pl.seed_everything(config['random_seed'])\n",
    "\n",
    "        if pretraining_data_loader or model_from_checkpoint:\n",
    "\n",
    "            if model_from_checkpoint:\n",
    "                print('Using model from checkpoint')\n",
    "                \n",
    "                gpus = 1 if torch.cuda.is_available() else 0\n",
    "                model = model_from_checkpoint\n",
    "\n",
    "            model.set_max_epochs(config['finetuning-epochs'])\n",
    "            model.set_learningrate(config['finetuning-learningrate'])\n",
    "            model.set_batchsize(config['finetuning-batchsize'])\n",
    "\n",
    "        else:\n",
    "\n",
    "            model, gpus = get_model(\n",
    "                _max_epochs=config['finetuning-epochs'],\n",
    "                batchsize=config['finetuning-batchsize'],\n",
    "                projection_head_out=config['projection_head_out'],\n",
    "                learning_rate=config['finetuning-learningrate'],\n",
    "                optimizer=config['optimizer'],\n",
    "                pretrained=pretrained\n",
    "            )\n",
    "\n",
    "        trainer = train_model(\n",
    "            _model=model,\n",
    "            _max_epochs=config['finetuning-epochs'],\n",
    "            _gpus=gpus,\n",
    "            dataloader=finetuning_data_loader,\n",
    "            _logger=logger,\n",
    "            log_every_n_steps=finetuning_log_every_n_steps\n",
    "        )\n",
    "\n",
    "        trainer.save_checkpoint(f'{config[\"logs_base_folder\"]}/{_experiment_name}/{version_name}/final_model_checkpoints/{version_name}.ckpt')\n",
    "\n",
    "\n",
    "    no_training_at_all = pretraining_data_loader == None and finetuning_data_loader == None\n",
    "    \n",
    "    if no_training_at_all:\n",
    "        print('No training at all...')\n",
    "        version_name = f'{datetime.now().strftime(\"%y-%m-%d-%H%M%S\")}'\n",
    "        \n",
    "        if model_from_checkpoint:\n",
    "            print('Using model from checkpoint')\n",
    "            model = model_from_checkpoint\n",
    "        else:\n",
    "            print('Initializing new model. Pretrained: ', pretrained)\n",
    "            model, gpus = get_model(\n",
    "                _max_epochs=config['pretraining-epochs'],\n",
    "                batchsize=config['pretraining-batchsize'],\n",
    "                projection_head_out=config['projection_head_out'],\n",
    "                learning_rate=config['pretraining-learningrate'],\n",
    "                optimizer=config['optimizer'],\n",
    "                pretrained=pretrained\n",
    "            )\n",
    "\n",
    "\n",
    "    # make embeddings\n",
    "    model.eval()\n",
    "    embeddings, filenames = generate_embeddings(model, test_data_loader)\n",
    "    print(embeddings)\n",
    "    # store embeddings and filenames    \n",
    "    embbedings_saving_folder = f'{config[\"logs_base_folder\"]}/{_experiment_name}/{version_name}/embeddings'\n",
    "\n",
    "    os.makedirs(embbedings_saving_folder)\n",
    "\n",
    "    np.save(f'{embbedings_saving_folder}/embeddings', embeddings)\n",
    "    filenames_file = open(f'{embbedings_saving_folder}/embeddings_filenames.pickle', 'wb')\n",
    "    pickle.dump(filenames, filenames_file)\n",
    "    filenames_file.close()\n",
    "    \n",
    "\n",
    "    # make knn and visualize neighbours of embeddings\n",
    "    knn = get_knn(_embeddings=embeddings, n_neighbours=30)\n",
    "    \n",
    "    path_to_data = config['path_to_dew_data'] if do_not_use_hzille_metadata else config['path_to_hzille_data']\n",
    "    print(path_to_data)\n",
    "\n",
    "    plot_knn_examples(\n",
    "        _knn=knn, \n",
    "        _embeddings=embeddings,\n",
    "        _filenames=filenames,\n",
    "        path_to_data=path_to_data,\n",
    "        num_examples=30,\n",
    "        plot_saving_folder=f'{config[\"logs_base_folder\"]}/{_experiment_name}/{version_name}/knn_plots/',\n",
    "        fig_size=config['plot_fig_size'],\n",
    "        seed=config['random_seed']\n",
    "    )\n",
    "\n",
    "\n",
    "    # plot embeddings via pca/tsne\n",
    "    hzille_metadata_path = None if do_not_use_hzille_metadata else config['hzille_metadata_path']\n",
    "\n",
    "    visualize_embeddings(\n",
    "        embeddings=embeddings,\n",
    "        filenames=filenames,\n",
    "        hzille_metadata_path=hzille_metadata_path,\n",
    "        path_to_store_data=f'{config[\"logs_base_folder\"]}/{_experiment_name}/{version_name}',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0f5egq3tsLy7"
   },
   "outputs": [],
   "source": [
    "def init_experiments():\n",
    "    print(global_config)\n",
    "    print()\n",
    "\n",
    "    connect_to_gdrive()\n",
    "    pl.seed_everything(global_config['random_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RtESTe9jviJe",
    "outputId": "ea180e2a-befc-4ca9-eb28-0f3bffabac92"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QQycT5Q0tFl_",
    "outputId": "c00b4a87-7b62-43be-936c-d6da542b8cb7",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Connect to drive and set global seed for torch\n",
    "\"\"\"\n",
    "init_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "03PeFPSuHMMN"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "days3rGaPzVK"
   },
   "outputs": [],
   "source": [
    "#!kill 3385"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "My7nbnJBZz2o"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create Heinrich Zille images dataloader.\n",
    "Batch size differs from using dew due to the smaller size of the dataset (675)\n",
    "\"\"\"\n",
    "dataloader_hzille_train, dataloader_hzille_test = load_hzille_data(\n",
    "    batch_size=global_config['finetuning-batchsize']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "glxea_FWYIQ5"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create dew dataloader\n",
    "\"\"\"\n",
    "dataloader_dew_train, dataloader_dew_test = load_dew_data(\n",
    "    batch_size=global_config['pretraining-batchsize']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2CbR1Jp0xMH"
   },
   "outputs": [],
   "source": [
    "#!rm -r runs/9_dew_only_pretrained/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2DXj3kurQ9R"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment 0:\n",
    "\n",
    "Use UNTRAINED resnet on Heinrich Zille images \n",
    "and test on Heinrich Zille images\n",
    "\"\"\"\n",
    "\n",
    "experiment_name = '0_hzille_untrained'\n",
    "\n",
    "run_experiment(\n",
    "    _experiment_name=experiment_name,\n",
    "    config=global_config,\n",
    "    pretrained=False,\n",
    "    test_data_loader=dataloader_hzille_test\n",
    ")\n",
    "\n",
    "!cp -r /content/runs/0_hzille_untrained /content/drive/MyDrive/ML_logs/HZille/0_hzille_untrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "soPhQdYzjAjB"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment 1:\n",
    "\n",
    "Use PRETRAINED (ImageNet, torchvision) resnet on Heinrich Zille images\n",
    "and test on Heinrich Zille images\n",
    "\"\"\"\n",
    "experiment_name = '1_hzille_only_pretrained'\n",
    "\n",
    "run_experiment(\n",
    "    _experiment_name=experiment_name,\n",
    "    config=global_config,\n",
    "    pretrained=True,\n",
    "    test_data_loader=dataloader_hzille_test,\n",
    ")\n",
    "\n",
    "!cp -r /content/runs/1_hzille_only_pretrained /content/drive/MyDrive/ML_logs/HZille/1_hzille_only_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8SpbW6wAh5o"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment 2:\n",
    "\n",
    "Use PRETRAINED (ImageNet, torchvision) resnet,\n",
    "FINETUNE with SimCLR on Heinrich Zille images,\n",
    "and test on Heinrich Zille images\n",
    "\"\"\"\n",
    "experiment_name = '2_hzille_pretrained_finetuned'\n",
    "\n",
    "run_experiment(\n",
    "    _experiment_name=experiment_name,\n",
    "    config=global_config,\n",
    "    pretrained=True,\n",
    "    finetuning_dataset_name='hzille',\n",
    "    finetuning_data_loader=dataloader_hzille_train,\n",
    "    test_data_loader=dataloader_hzille_test\n",
    ")\n",
    "\n",
    "!cp -r /content/runs/2_hzille_pretrained_finetuned /content/drive/MyDrive/ML_logs/HZille/2_hzille_pretrained_finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HydC_h1Gkv3u"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment 3:\n",
    "\n",
    "Use PRETRAINED (ImageNet, torchvision) resnet,\n",
    "OVERTRAIN with SimCLR and dew dataset, \n",
    "and test on Heinrich Zille images \n",
    "\"\"\"\n",
    "experiment_name = '3_hzille_overtrain'\n",
    "\n",
    "run_experiment(\n",
    "    _experiment_name=experiment_name,\n",
    "    config=global_config,\n",
    "    pretrained=True,\n",
    "    pretraining_dataset_name='dew',\n",
    "    pretraining_data_loader=dataloader_dew_train,\n",
    "    test_data_loader=dataloader_hzille_test\n",
    ")\n",
    "\n",
    "!cp -r /content/runs/3_hzille_overtrain /content/drive/MyDrive/ML_logs/HZille/3_hzille_overtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IneQ-TSQlJhB"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment 4:\n",
    "\n",
    "Use PRETRAINED (ImageNet, torchvision) resnet,\n",
    "OVERTRAINED with SimCLR and dew dataset,\n",
    "FINETUNED on Heinrich Zille images\n",
    "and test on Heinricht Zille images\n",
    "\"\"\"\n",
    "\n",
    "#load model checkpoints from experiment 3, as experiment 4 is building up on it\n",
    "checkpoint_path = 'runs/3_hzille_overtrain/22-02-21-120301_pretraining_dew/final_model_checkpoints/22-02-21-120301_pretraining_dew.ckpt'\n",
    "loaded_model = ResnetSimCLR.load_from_checkpoint(\n",
    "    checkpoint_path,\n",
    "    max_epochs=global_config['pretraining-epochs'],\n",
    "    batchsize=global_config['pretraining-batchsize'],\n",
    "    projection_head_out=global_config['projection_head_out'],\n",
    "    learning_rate=global_config['pretraining-learningrate'],\n",
    "    optimizer=global_config['optimizer']\n",
    ")\n",
    "\n",
    "experiment_name = '4_hzille_overtrain_finetune'\n",
    "\n",
    "run_experiment(\n",
    "    _experiment_name=experiment_name,\n",
    "    config=global_config,\n",
    "    pretrained=True,\n",
    "    #pretraining_dataset_name='dew',\n",
    "    #pretraining_data_loader=dataloader_dew_train,\n",
    "    finetuning_dataset_name='hzille',\n",
    "    finetuning_data_loader=dataloader_hzille_train,\n",
    "    test_data_loader=dataloader_hzille_test,\n",
    "    model_from_checkpoint=loaded_model\n",
    ")\n",
    "\n",
    "!cp -r /content/runs/4_hzille_overtrain_finetune /content/drive/MyDrive/ML_logs/HZille/4_hzille_overtrain_finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "j1nBib34msIO"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment 5:\n",
    "\n",
    "Use UNTRAINED (ImageNet, torchvision) resnet,\n",
    "TRAIN with SimCLR and dew dataset,\n",
    "and test on Heinrich Zille images\n",
    "\"\"\"\n",
    "experiment_name = '5_hzille_train'\n",
    "\n",
    "run_experiment(\n",
    "    _experiment_name=experiment_name,\n",
    "    config=global_config,\n",
    "    pretrained=False,\n",
    "    pretraining_dataset_name='dew',\n",
    "    pretraining_data_loader=dataloader_dew_train,\n",
    "    test_data_loader=dataloader_hzille_test\n",
    ")\n",
    "\n",
    "!cp -r /content/runs/5_hzille_train /content/drive/MyDrive/ML_logs/HZille/5_hzille_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-qrlUNsnBVh"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment 6:\n",
    "\n",
    "Use UNTRAINED (ImageNet, torchvision) resnet,\n",
    "TRAIN with SimCLR and dew dataset,\n",
    "FINETUNE with SimCLR on Heinrich Zille images \n",
    "and test on Heinrich Zille images\n",
    "\"\"\"\n",
    "\n",
    "#load model checkpoints from experiment 5, as experiment 6 is building up on it\n",
    "checkpoint_path = '/content/drive/MyDrive/ML_logs/HZille/5_hzille_train/22-02-21-204646_pretraining_dew/final_model_checkpoints/22-02-21-204646_pretraining_dew.ckpt'\n",
    "\n",
    "loaded_model = ResnetSimCLR.load_from_checkpoint(\n",
    "    checkpoint_path,\n",
    "    max_epochs=global_config['pretraining-epochs'],\n",
    "    batchsize=global_config['pretraining-batchsize'],\n",
    "    projection_head_out=global_config['projection_head_out'],\n",
    "    learning_rate=global_config['pretraining-learningrate'],\n",
    "    optimizer=global_config['optimizer']\n",
    ")\n",
    "\n",
    "experiment_name = '6_hzille_train_finetune'\n",
    "\n",
    "run_experiment(\n",
    "    _experiment_name=experiment_name,\n",
    "    config=global_config,\n",
    "    pretrained=False,\n",
    "    #pretraining_dataset_name='dew',\n",
    "    #pretraining_data_loader=dataloader_dew_train,\n",
    "    finetuning_dataset_name='hzille',\n",
    "    finetuning_data_loader=dataloader_hzille_train,\n",
    "    test_data_loader=dataloader_hzille_test,\n",
    "    model_from_checkpoint=loaded_model\n",
    ")\n",
    "\n",
    "!cp -r /content/runs/6_hzille_train_finetune /content/drive/MyDrive/ML_logs/HZille/6_hzille_train_finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "atbcybfnnv5l"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment 7:\n",
    "\n",
    "Use UNTRAINED (ImageNet, torchvision) resnet,\n",
    "TRAIN with Heinrich Zille dataset,\n",
    "and test on Heinrich Zille images\n",
    "\"\"\"\n",
    "experiment_name = '7_hzille_train'\n",
    "\n",
    "run_experiment(\n",
    "    _experiment_name=experiment_name,\n",
    "    config=global_config,\n",
    "    pretrained=False,\n",
    "    pretraining_dataset_name='hzille',\n",
    "    pretraining_data_loader=dataloader_hzille_train,\n",
    "    test_data_loader=dataloader_hzille_test,\n",
    "    pretraining_log_every_n_steps=3,\n",
    "    forced_batch_size_in_pretraining=global_config['finetuning-batchsize']\n",
    ")\n",
    "\n",
    "!cp -r /content/runs/7_hzille_train /content/drive/MyDrive/ML_logs/HZille/7_hzille_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W0PTIYsfoDyd"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment 8:\n",
    "\n",
    "Use PRETRAINED (ImageNet, torchvision) resnet,\n",
    "TRAIN with Heinrich Zille dataset,\n",
    "and test on Heinrich Zille images\n",
    "\"\"\"\n",
    "experiment_name = '8_hzille_overtrain'\n",
    "\n",
    "run_experiment(\n",
    "    _experiment_name=experiment_name,\n",
    "    config=global_config,\n",
    "    pretrained=True,\n",
    "    pretraining_dataset_name='hzille',\n",
    "    pretraining_data_loader=dataloader_hzille_train,\n",
    "    test_data_loader=dataloader_hzille_test,\n",
    "    pretraining_log_every_n_steps=3,\n",
    "    forced_batch_size_in_pretraining=global_config['finetuning-batchsize']\n",
    ")\n",
    "\n",
    "!cp -r /content/runs/8_hzille_overtrain /content/drive/MyDrive/ML_logs/HZille/8_hzille_overtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o-RW_RaoVAz_"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment 9 (only dew):\n",
    "\n",
    "Use PRETRAINED (ImageNet, torchvision) resnet,\n",
    "and test on dew\n",
    "\"\"\"\n",
    "\n",
    "experiment_name = '9_dew_only_pretrained'\n",
    "\n",
    "run_experiment(\n",
    "    _experiment_name=experiment_name,\n",
    "    config=global_config,\n",
    "    pretrained=True,\n",
    "    test_data_loader=dataloader_dew_test,\n",
    "    do_not_use_hzille_metadata=True\n",
    ")\n",
    "\n",
    "!cp -r /content/runs/9_dew_only_pretrained /content/drive/MyDrive/ML_logs/HZille/9_dew_only_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3GoazbuFh-D3"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment 10 (only dew):\n",
    "\n",
    "Use PRETRAINED (ImageNet, torchvision) resnet,\n",
    "OVERTRAIN with SimCLR and dew images,\n",
    "and test on dew images\n",
    "\"\"\"\n",
    "\n",
    "#load model checkpoints from experiment 3, as experiment 10 is building up on it\n",
    "checkpoint_path = '/content/drive/MyDrive/ML_logs/HZille/3_hzille_overtrain/22-02-21-120301_pretraining_dew/final_model_checkpoints/22-02-21-120301_pretraining_dew.ckpt'\n",
    "loaded_model = ResnetSimCLR.load_from_checkpoint(\n",
    "    checkpoint_path,\n",
    "    max_epochs=global_config['pretraining-epochs'],\n",
    "    batchsize=global_config['pretraining-batchsize'],\n",
    "    projection_head_out=global_config['projection_head_out'],\n",
    "    learning_rate=global_config['pretraining-learningrate'],\n",
    "    optimizer=global_config['optimizer']\n",
    ")\n",
    "\n",
    "experiment_name = '10_dew_overtrain'\n",
    "\n",
    "run_experiment(\n",
    "    _experiment_name=experiment_name,\n",
    "    config=global_config,\n",
    "    pretrained=True,\n",
    "    #pretraining_dataset_name='dew',\n",
    "    #pretraining_data_loader=dataloader_dew_train,\n",
    "    test_data_loader=dataloader_dew_test,\n",
    "    model_from_checkpoint=loaded_model\n",
    ")\n",
    "\n",
    "!cp -r /content/runs/10_dew_overtrain /content/drive/MyDrive/ML_logs/HZille/10_dew_overtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJcQe1022yp1"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment 11 (only dew):\n",
    "\n",
    "Use UNTRAINED (ImageNet, torchvision) resnet,\n",
    "TRAIN with SimCLR and dew images,\n",
    "and visualize dew images\n",
    "\"\"\"\n",
    "#load model checkpoints from experiment 5, as experiment 10 is building up on it\n",
    "checkpoint_path = '/content/drive/MyDrive/ML_logs/HZille/5_hzille_train/22-02-21-204646_pretraining_dew/final_model_checkpoints/22-02-21-204646_pretraining_dew.ckpt'\n",
    "loaded_model = ResnetSimCLR.load_from_checkpoint(\n",
    "    checkpoint_path,\n",
    "    max_epochs=global_config['pretraining-epochs'],\n",
    "    batchsize=global_config['pretraining-batchsize'],\n",
    "    projection_head_out=global_config['projection_head_out'],\n",
    "    learning_rate=global_config['pretraining-learningrate'],\n",
    "    optimizer=global_config['optimizer']\n",
    ")\n",
    "\n",
    "experiment_name = '11_dew_train'\n",
    "\n",
    "run_experiment(\n",
    "    _experiment_name=experiment_name,\n",
    "    config=global_config,\n",
    "    pretrained=False,\n",
    "    #pretraining_dataset_name='dew',\n",
    "    #pretraining_data_loader=dataloader_dew_train,\n",
    "    test_data_loader=dataloader_dew_test,\n",
    "    model_from_checkpoint=loaded_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EKadrvog7_-Z"
   },
   "outputs": [],
   "source": [
    "plot_data_augmentations(dataloader_hzille_train)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "plot_data_augmentations(dataloader_hzille_train)"
   ],
   "metadata": {
    "id": "XC0vxh2xgrd9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot_data_augmentations(dataloader_dew_train)"
   ],
   "metadata": {
    "id": "Chs0fOkTgszu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_all_hzille_test_images():\n",
    "    \n",
    "    filenames_filename = 'embeddings_filenames.pickle'\n",
    "    embeddings_path = '/content/drive/MyDrive/ML_logs/HZille/0_hzille_untrained/22-02-20-211630/embeddings/'\n",
    "    path_to_data = 'drive/MyDrive/Data Sets/Heinrich Zille/ausgeschnitten_klein/'\n",
    "\n",
    "    rows = 10\n",
    "    columns = 20\n",
    "\n",
    "    opened_pickle_file = open(f'{embeddings_path}{filenames_filename}', 'rb')\n",
    "    filenames = pickle.load(opened_pickle_file)\n",
    "    opened_pickle_file.close()\n",
    "    \n",
    "    print(len(filenames), 'images')\n",
    "\n",
    "    fig = plt.figure(figsize=(160, 50))\n",
    "\n",
    "    for i, filename in enumerate(filenames):\n",
    "        #print(i, filename)\n",
    "        fig.add_subplot(rows, columns, i + 1)\n",
    "        img = get_image_as_np_array(f'{path_to_data}{filename}')\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'{i} - {filename}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compare_nearest_neighbours_of_all_experiments(image_index):\n",
    "    \n",
    "    filenames_filename = 'embeddings_filenames.pickle'\n",
    "    embeddings_file_name = 'embeddings.npy'\n",
    "    \n",
    "    embeddings_pathes = [\n",
    "        '/content/drive/MyDrive/ML_logs/HZille/0_hzille_untrained/22-02-20-211630/embeddings/',\n",
    "        '/content/drive/MyDrive/ML_logs/HZille/1_hzille_only_pretrained/22-02-20-211922/embeddings/',\n",
    "        '/content/drive/MyDrive/ML_logs/HZille/2_hzille_pretrained_finetuned/22-02-21-114830_finetuning_hzille/embeddings/',\n",
    "        '/content/drive/MyDrive/ML_logs/HZille/3_hzille_overtrain/22-02-21-120301_pretraining_dew/embeddings/',\n",
    "        '/content/drive/MyDrive/ML_logs/HZille/4_hzille_overtrain_finetune/22-02-21-201901_finetuning_hzille/embeddings/',\n",
    "        '/content/drive/MyDrive/ML_logs/HZille/5_hzille_train/22-02-21-204646_pretraining_dew/embeddings/',\n",
    "        '/content/drive/MyDrive/ML_logs/HZille/6_hzille_train_finetune/22-02-22-081633_finetuning_hzille/embeddings/',\n",
    "        '/content/drive/MyDrive/ML_logs/HZille/7_hzille_train/22-02-22-084656_pretraining_hzille/embeddings/',\n",
    "        '/content/drive/MyDrive/ML_logs/HZille/8_hzille_overtrain/22-02-22-085652_pretraining_hzille/embeddings/'\n",
    "    ]\n",
    "\n",
    "    path_to_data = 'drive/MyDrive/Data Sets/Heinrich Zille/ausgeschnitten_klein/'\n",
    "\n",
    "    opened_pickle_file = open(f'{embeddings_pathes[0]}{filenames_filename}', 'rb')\n",
    "    filenames = pickle.load(opened_pickle_file)\n",
    "    opened_pickle_file.close()\n",
    "\n",
    "    num_nearest_neighbours = 10\n",
    "\n",
    "    rows = len(embeddings_pathes)\n",
    "    columns = num_nearest_neighbours\n",
    "\n",
    "    fig = plt.figure(figsize=(50, 40))\n",
    "\n",
    "    img_position_in_plot = 1\n",
    "\n",
    "    for embeddings_path in embeddings_pathes:\n",
    "\n",
    "        embeddings = np.load(f'{embeddings_path}{embeddings_file_name}')\n",
    "        knn = NearestNeighbors(n_neighbors=num_nearest_neighbours).fit(embeddings)\n",
    "\n",
    "        distances, indices = knn.kneighbors(embeddings)\n",
    "        \n",
    "        selected_img_and_neighbours = indices[image_index]\n",
    "\n",
    "        for i, neighbour_i in enumerate(selected_img_and_neighbours):\n",
    "            \n",
    "            #print(i, filename)\n",
    "            \n",
    "            ax = fig.add_subplot(rows, columns, img_position_in_plot)\n",
    "\n",
    "            img = get_image_as_np_array(f'{path_to_data}{filenames[neighbour_i]}')\n",
    "            \n",
    "            ax.set_title(f'd={distances[image_index][i]:.3f} ({filenames[neighbour_i]})')\n",
    "            plt.axis('off')\n",
    "            plt.imshow(img, cmap='gray')\n",
    "\n",
    "            img_position_in_plot += 1 \n",
    "\n",
    "        # break\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "eIkhFh8l1ljw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "compare_nearest_neighbours_of_all_experiments(image_index=100)"
   ],
   "metadata": {
    "id": "HLK7fcTnXssp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "compare_nearest_neighbours_of_all_experiments(image_index=107)"
   ],
   "metadata": {
    "id": "f2-jWFfAYgdC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "compare_nearest_neighbours_of_all_experiments(image_index=103)"
   ],
   "metadata": {
    "id": "Y8AzPfDvW2Gu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "compare_nearest_neighbours_of_all_experiments(image_index=46)"
   ],
   "metadata": {
    "id": "Y3d7WKZeUpdZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "compare_nearest_neighbours_of_all_experiments(image_index=27)"
   ],
   "metadata": {
    "id": "OuEH3ZMBS6gZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "compare_nearest_neighbours_of_all_experiments(image_index=15)"
   ],
   "metadata": {
    "id": "xRVmkca2R3Lg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "compare_nearest_neighbours_of_all_experiments(image_index=14)"
   ],
   "metadata": {
    "id": "a-5GNTHHRJOn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "compare_nearest_neighbours_of_all_experiments(image_index=8)"
   ],
   "metadata": {
    "id": "gNqyvAm8QgZ9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "compare_nearest_neighbours_of_all_experiments(image_index=0)"
   ],
   "metadata": {
    "id": "eINheH7IGGem"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot_all_hzille_test_images()"
   ],
   "metadata": {
    "id": "eXRUzC1c6t-R"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Plot all cluster in t-SNE plots \n",
    "and all images of the clusters\n",
    "\"\"\"\n",
    "\n",
    "dim_reduction_pathes = [\n",
    "    '/content/drive/MyDrive/ML_logs/HZille/0_hzille_untrained/22-02-20-211630/dim_reduction/',\n",
    "    '/content/drive/MyDrive/ML_logs/HZille/1_hzille_only_pretrained/22-02-20-211922/dim_reduction/',\n",
    "    '/content/drive/MyDrive/ML_logs/HZille/2_hzille_pretrained_finetuned/22-02-21-114830_finetuning_hzille/dim_reduction/',\n",
    "    '/content/drive/MyDrive/ML_logs/HZille/3_hzille_overtrain/22-02-21-120301_pretraining_dew/dim_reduction/',\n",
    "    '/content/drive/MyDrive/ML_logs/HZille/4_hzille_overtrain_finetune/22-02-21-201901_finetuning_hzille/dim_reduction/',\n",
    "    '/content/drive/MyDrive/ML_logs/HZille/5_hzille_train/22-02-21-204646_pretraining_dew/dim_reduction/',\n",
    "    '/content/drive/MyDrive/ML_logs/HZille/6_hzille_train_finetune/22-02-22-081633_finetuning_hzille/dim_reduction/',\n",
    "    '/content/drive/MyDrive/ML_logs/HZille/7_hzille_train/22-02-22-084656_pretraining_hzille/dim_reduction/',\n",
    "    '/content/drive/MyDrive/ML_logs/HZille/8_hzille_overtrain/22-02-22-085652_pretraining_hzille/dim_reduction/'\n",
    "]\n",
    "\n",
    "path_to_data = 'drive/MyDrive/Data Sets/Heinrich Zille/ausgeschnitten_klein/'\n",
    "\n",
    "dim_reduction_technique = 'tsne'\n",
    "no_dimensions = 3\n",
    "\n",
    "n_clusters = 9\n",
    "\n",
    "\n",
    "for experiment_no, path in enumerate(dim_reduction_pathes):\n",
    "\n",
    "    print('Processing experiment', experiment_no)\n",
    "\n",
    "    df = pd.read_csv(f'{path}{dim_reduction_technique}_{no_dimensions}d.csv', index_col=0)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=global_config['random_seed'], max_iter=300, n_init=10, tol=1e-4).fit(df[['0', '1', '2']])\n",
    "    # centroids = kmeans.cluster_centers_\n",
    "    cluster_labels = [str(label) for label in kmeans.labels_]\n",
    "\n",
    "    #total_within_cluster_distances = []\n",
    "    #for i in range(1, 20):\n",
    "    #    kmeans = KMeans(n_clusters=i, random_state=global_config['random_seed'], max_iter=500, n_init=20, tol=1e-4).fit(df[['0', '1', '2']])\n",
    "    #    total_within_cluster_distances.append(kmeans.inertia_)\n",
    "    #    \n",
    "    #fig = go.Figure(data = go.Scatter(x = list(range(1,21)), y = total_within_cluster_distances))\n",
    "    #\n",
    "    #\n",
    "    #fig.update_layout(title='Total Within Cluster Distances per Cluster',\n",
    "    #                   xaxis_title='Cluster no.',\n",
    "    #                   yaxis_title='Total Within Cluster Distance')\n",
    "    #fig.show()\n",
    "\n",
    "\n",
    "    fig = px.scatter_3d(\n",
    "        df,\n",
    "        x='0',\n",
    "        y='1',\n",
    "        z='2',\n",
    "        color=cluster_labels,\n",
    "        symbol='author',\n",
    "        hover_data=['id'],\n",
    "        labels={\n",
    "            '0': '1st projection',\n",
    "            '1': '2nd projection',\n",
    "            '2': '3rd projection',\n",
    "            'color' : 'cluster'\n",
    "        },\n",
    "        title=f'Experiment {experiment_no} - t-SNE 3D - {n_clusters} clusters (kmeans)'\n",
    "    )\n",
    "    fig.update_traces(marker_size=6)\n",
    "\n",
    "    fig.show()\n",
    "    fig.write_html(f'/content/drive/MyDrive/ML_logs/HZille/cluster_plots/experiment_{experiment_no}.html')\n",
    "\n",
    "    rows = 4\n",
    "    columns = 10\n",
    "\n",
    "    df['cluster'] = cluster_labels\n",
    "\n",
    "    for cluster in df['cluster'].unique():\n",
    "        print('Plotting cluster', cluster)\n",
    "        \n",
    "        fig = plt.figure(figsize=(60, 20))\n",
    "        fig.suptitle(f'Experiment {experiment_no} cluster {cluster}', fontsize=16)\n",
    "\n",
    "        selected_images = df[df['cluster'] == cluster]['id']\n",
    "\n",
    "        for i, img_id in enumerate(selected_images):\n",
    "            #print(i, img_id)\n",
    "\n",
    "            fig.add_subplot(rows, columns, i + 1)\n",
    "            img = get_image_as_np_array(f'{path_to_data}{img_id}.jpg')\n",
    "            plt.imshow(img, cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title(f'{img_id}.jpg')\n",
    "\n",
    "        fig.savefig(f'/content/drive/MyDrive/ML_logs/HZille/cluster_plots/experiment_{experiment_no}_cluster_{cluster}.jpg')"
   ],
   "metadata": {
    "id": "HrisfebinXJ8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Plot random samples of dew dataset\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "filenames_file = 'drive/MyDrive/Data Sets/dew/until_1950/until_1950.pickle'\n",
    "path_to_data = 'drive/MyDrive/Data Sets/dew/until_1950/until_1950/'\n",
    "\n",
    "rows = 6\n",
    "columns = 8\n",
    "\n",
    "opened_pickle_file = open(filenames_file, 'rb')\n",
    "filenames = pickle.load(opened_pickle_file)\n",
    "opened_pickle_file.close()\n",
    "\n",
    "samples_indices = np.random.choice(len(filenames), size=rows*columns, replace=False)\n",
    "\n",
    "print('sample indices', samples_indices)\n",
    "\n",
    "selected_filenames = [\n",
    "    filename for i, filename in enumerate(filenames) if i in samples_indices\n",
    "]\n",
    "\n",
    "print('selected images', len(selected_filenames), selected_filenames)\n",
    "\n",
    "fig = plt.figure(figsize=(60, 80))\n",
    "\n",
    "for i, filename in enumerate(selected_filenames):\n",
    "    print(i, filename)\n",
    "    fig.add_subplot(rows, columns, i + 1)\n",
    "    img = get_image_as_np_array(f'{path_to_data}{filename}')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'{i} - {filename}')"
   ],
   "metadata": {
    "id": "0Wkhplso722K"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    ""
   ],
   "metadata": {
    "id": "VuGWDd0jIXnw"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "learning_hzille.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}